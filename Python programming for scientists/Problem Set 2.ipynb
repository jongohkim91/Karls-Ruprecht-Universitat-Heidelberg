{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Problem Set 2 - Arctic ice maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Total points:** 30\n",
    "\n",
    "**Due:** Friday October 13th, 7pm CEST\n",
    "\n",
    "**Format:** IPython Notebook or python program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this problem set is to become familiar with working with image data, plotting it, and combining it in various ways for analysis.\n",
    "\n",
    "The data used in this problem set was collected by the AMSR-E instrument [Aqua](http://en.wikipedia.org/wiki/Aqua_%28satellite%29) satellite. The data consists of maps of the concentration of ice in the Arctic collected between 2006 and 2011. The data were downloaded and extracted from [here](http://www.iup.uni-bremen.de/seaice/amsr/) and converted into a format that can be more easily used.\n",
    "\n",
    "The data you should use is in [here](http://wwwstaff.ari.uni-heidelberg.de/rschmidt/pycourse/ice_data.tgz) (use [this link](http://wwwstaff.ari.uni-heidelberg.de/rschmidt/pycourse/ice_data.zip) if you need a zip archive) and can also be accessed in ``/local/py4sci/ice_data`` if you are using the CIP computers (no need to copy over that directory, just read the files from there).  To use it, copy the tgz file into your day3 directory and type:\n",
    "\n",
    "     tar -xvzf ice.tgz\n",
    "\n",
    "The data is in 'Numpy' format, which means that you can read it as a Numpy array using:\n",
    "\n",
    "    >>> import numpy as np\n",
    "    >>> data = np.load('ice_data/20080415.npy')\n",
    "\n",
    "which will give you a 2-d array. Just for information, this was created with:\n",
    "\n",
    "    >>> np.save('ice_data/20080415.npy', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - examining a single map (6 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Start off by reading in one of the maps as shown above, and plot it with Matplotlib**. Note that to get the correct orientation, you will need to call the ``imshow`` command with the ``origin='lower'`` option, which ensures that the (0,0) pixels is on the bottom left, not the top left. You can try and use different colormaps if you like (set by the ``cmap`` option) - see [here](http://www.scipy.org/Cookbook/Matplotlib/Show_colormaps) for information on the available colormaps. You can specify a colormap to use with e.g. ``cmap=plt.cm.jet`` (i.e. ``cmap=plt.cm.`` followed by the name of the colormap). Note that you can make figures larger by specifying e.g.\n",
    "\n",
    "    >>> plt.figure(figsize=(8,8))\n",
    "\n",
    "where the size is given in inches. Try and find a way to plot a colorbar on the side, to show what color corresponds to what value. Examples can be found in the [Matplotlib Gallery](http://matplotlib.org/gallery.html). You may also want to try to remove the tick labels (``100``, ``200``, etc.) since they are not useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - reading in multiple maps (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to make a plot of the ice concentration over time. Reading in a single map is easy, but since we have 137 maps, we do not want to read them all in individually by hand. **Write a loop over all the available files, and inside the loop, read in the data to a variable (e.g. ``data``), and also extract the year, month, and day as integer values (e.g. ``year``, ``month``, and ``day``)**. Then, also inside the loop, **compute a variable ``time``** which is essentially the fractional time in years (so 1st July 2012 is 2012.5). You can assume for simplicity that each month has 30 days - this will not affect the results later. Finally, also **compute for each file the total number of pixels that have a value above 50%**. After the loop, **make a plot of the number of pixels with a concentration above 50% against time**.\n",
    "\n",
    "You will likely notice that the ticks are in a strange format, where they are given in years since 2006, but you can change this with the following code:\n",
    "\n",
    "    >>> from matplotlib.ticker import ScalarFormatter\n",
    "    >>> plt.gca().xaxis.set_major_formatter(ScalarFormatter(useOffset=False))\n",
    "\n",
    "**Describe what you see in the plot**.\n",
    "\n",
    "We now want something a little more quantitative than just the number of pixels, so we will try and compute the area where the ice concentration is above a given threshold. However, we first need to know the area of the pixels in the image, and since we are looking at a projection of a spherical surface, each pixel will be a different area. The areas (in km^2) are contained inside the file named ``ice_data_area.npy`` (if you are using the CIP pool, this is ``/local/py4sci/ice_data_area.npy``). **Read in the areas and make a plot (with colorbar) to see how the pixel area is changing over the image.**\n",
    "\n",
    "Now, loop over the files again as before, but this time, for each file, **compute the total area where the concentration of ice is 99% or above. Make a new plot showing the area of >99% ice concentration against time.**\n",
    "\n",
    "**Describe what you see - how does the minimum change over time?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - visualizing changes over time (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find the date at which the area of the region where the ice concentration is above 99% is the smallest**. What is the value of the minimum area?\n",
    "\n",
    "Next, **read in the map for this minimum, and the map for the same day and month but from 2006**. **Make a side-by-side plot showing the 2006 and the 2011 data**.\n",
    "\n",
    "**Compute the difference between the two maps** so that a loss in ice over time will correspond to a negative value, and a gain in ice will correspond to a positive value. **Make a plot** of the difference, and use the ``RdBu`` colormap to highlight the changes (include a colorbar)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - yearly averages (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute average ice concentration maps for 2006 and 2011, and plot them side by side.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epilogue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data that we have here only cover five years, so we cannot reliably extract information about long term trends. However, it is worth noting that the minimum ice coverage you found here was a record minimum - never before (in recorded history) had the size of the ice shelf been so small. This is part of a long term trend due to global warming. In 2012, the record was again beaten, and most scientists believe that by ~2050, the Arctic will be completely ice-free for at least part of the summer."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
